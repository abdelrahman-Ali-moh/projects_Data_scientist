{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Fraud    284315\n",
      "Fraud           492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_names = {0:'Not Fraud', 1:'Fraud'}\n",
    "print(df.Class.value_counts().rename(index = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=le.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85279    29]\n",
      " [   49    86]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,\n",
    "    pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity/Recall for Logistic Regression Model 1 : 0.64\n",
      "F1 :0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score\n",
    "f1_score = round(f1_score(y_test, pred), 2)\n",
    "recall_score = round(recall_score(y_test, pred), 2)\n",
    "print(\"Sensitivity/Recall for Logistic Regression Model 1 : {recall_score}\".format(recall_score = recall_score))\n",
    "print(\"F1 :{f1_score}\".format(f1_score = f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85308\n",
      "           1       0.75      0.64      0.69       135\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.87      0.82      0.84     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cc87cc2d48>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test, pred.round())\n",
    "\n",
    "sns.heatmap(cm,center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase ascore\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso=Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predec=lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0014996  0.00198352 0.00193646 ... 0.00249987 0.00135466 0.0025019 ]\n"
     ]
    }
   ],
   "source": [
    "print(predec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.16418543e-08 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85308\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.50      0.50      0.50     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score ,confusion_matrix,classification_report\n",
    "print(classification_report(y_test, predec.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
